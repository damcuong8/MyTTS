

import re
from typing import Optional


class VietnameseTTSNormalizer:
    """
    A text normalizer for Vietnamese Text-to-Speech.
    Converts numbers, dates, units, and special characters into readable Vietnamese text.
    """
    
    def __init__(self):
        # T·ª´ ƒëi·ªÉn ƒë∆°n v·ªã ƒëo l∆∞·ªùng
        self.units = {
            # ƒê∆°n v·ªã ƒëo chi·ªÅu d√†i
            'km': 'ki l√¥ m√©t', 'dm': 'ƒë√™ xi m√©t', 'cm': 'xen ti m√©t',
            'mm': 'mi li m√©t', 'nm': 'na n√¥ m√©t', '¬µm': 'mic r√¥ m√©t',
            'Œºm': 'mic r√¥ m√©t', 'm': 'm√©t',
            
            # ƒê∆°n v·ªã ƒëo kh·ªëi l∆∞·ª£ng
            'kg': 'ki l√¥ gam', 'g': 'gam', 'mg': 'mi li gam',
            
            # ƒê∆°n v·ªã ƒëo di·ªán t√≠ch
            'km¬≤': 'ki l√¥ m√©t vu√¥ng', 'km2': 'ki l√¥ m√©t vu√¥ng',
            'm¬≤': 'm√©t vu√¥ng', 'm2': 'm√©t vu√¥ng',
            'cm¬≤': 'xen ti m√©t vu√¥ng', 'cm2': 'xen ti m√©t vu√¥ng',
            'mm¬≤': 'mi li m√©t vu√¥ng', 'mm2': 'mi li m√©t vu√¥ng',
            'ha': 'h√©c ta',
            
            # ƒê∆°n v·ªã ƒëo th·ªÉ t√≠ch
            'km¬≥': 'ki l√¥ m√©t kh·ªëi', 'km3': 'ki l√¥ m√©t kh·ªëi',
            'm¬≥': 'm√©t kh·ªëi', 'm3': 'm√©t kh·ªëi',
            'cm¬≥': 'xen ti m√©t kh·ªëi', 'cm3': 'xen ti m√©t kh·ªëi',
            'mm¬≥': 'mi li m√©t kh·ªëi', 'mm3': 'mi li m√©t kh·ªëi',
            'l': 'l√≠t', 'dl': 'ƒë√™ xi l√≠t', 'ml': 'mi li l√≠t', 'hl': 'h√©c t√¥ l√≠t',
            
            # ƒê∆°n v·ªã ƒëi·ªán
            'v': 'v√¥n', 'kv': 'ki l√¥ v√¥n', 'mv': 'mi li v√¥n',
            'a': 'am pe', 'ma': 'mi li am pe', 'ka': 'ki l√¥ am pe',
            'w': 'o√°t', 'kw': 'ki l√¥ o√°t', 'mw': 'm√™ ga o√°t', 'gw': 'gi ga o√°t',
            'kwh': 'ki l√¥ o√°t gi·ªù', 'mwh': 'm√™ ga o√°t gi·ªù', 'wh': 'o√°t gi·ªù',
            'œâ': '√¥m', 'ohm': '√¥m', 'kœâ': 'ki l√¥ √¥m', 'mœâ': 'm√™ ga √¥m',
            
            # ƒê∆°n v·ªã t·∫ßn s·ªë
            'hz': 'h√©c', 'khz': 'ki l√¥ h√©c', 'mhz': 'm√™ ga h√©c', 'ghz': 'gi ga h√©c',
            
            # ƒê∆°n v·ªã √°p su·∫•t
            'pa': 'p√°t cal', 'kpa': 'ki l√¥ p√°t cal', 'mpa': 'm√™ ga p√°t cal',
            'bar': 'ba', 'mbar': 'mi li ba', 'atm': '√°t m·ªët phia', 'psi': 'pi √©t xai',
            
            # ƒê∆°n v·ªã nƒÉng l∆∞·ª£ng
            'j': 'giun', 'kj': 'ki l√¥ giun',
            'cal': 'ca lo', 'kcal': 'ki l√¥ ca lo',
        }
        
        # S·ªë ƒë·ªçc c∆° b·∫£n
        self.digits = ['kh√¥ng', 'm·ªôt', 'hai', 'ba', 'b·ªën', 
                       'nƒÉm', 's√°u', 'b·∫£y', 't√°m', 'ch√≠n']
    
    def normalize(self, text: str) -> str:
        """
        Main normalization pipeline.
        
        Args:
            text: Input text to normalize
            
        Returns:
            Normalized Vietnamese text
        """
        text = text.lower()
        

        text = self._normalize_temperature(text)
        text = self._normalize_currency(text)
        text = self._normalize_percentage(text)
        text = self._normalize_units(text)
        text = self._normalize_time(text)
        text = self._normalize_date(text)
        text = self._normalize_phone(text)
        text = self._normalize_numbers(text)
        text = self._number_to_words(text)
        text = self._normalize_special_chars(text)
        text = self._normalize_whitespace(text)
        
        return text
    
    def _normalize_temperature(self, text: str) -> str:
        """Convert temperature notation to words."""
        # Nhi·ªát ƒë·ªô √¢m
        text = re.sub(r'-([\d]+(?:[.,][\d]+)?)\s*¬∞\s*c\b', r'√¢m \1 ƒë·ªô x√™', text, flags=re.IGNORECASE)
        text = re.sub(r'-([\d]+(?:[.,][\d]+)?)\s*¬∞\s*f\b', r'√¢m \1 ƒë·ªô √©p', text, flags=re.IGNORECASE)
        
        # Nhi·ªát ƒë·ªô d∆∞∆°ng
        text = re.sub(r'([\d]+(?:[.,][\d]+)?)\s*¬∞\s*c\b', r'\1 ƒë·ªô x√™', text, flags=re.IGNORECASE)
        text = re.sub(r'([\d]+(?:[.,][\d]+)?)\s*¬∞\s*f\b', r'\1 ƒë·ªô √©p', text, flags=re.IGNORECASE)
        
        # K√Ω hi·ªáu ƒë·ªô ƒë∆°n l·∫ª
        text = re.sub(r'¬∞', ' ƒë·ªô ', text)
        
        return text
    
    def _normalize_currency(self, text: str) -> str:
        """Convert currency notation to words."""
        def decimal_currency(match):
            whole = match.group(1)
            decimal = match.group(2)
            unit = match.group(3)
            decimal_words = ' '.join([self.digits[int(d)] for d in decimal])
            unit_map = {'k': 'ngh√¨n', 'm': 'tri·ªáu', 'b': 't·ª∑'}
            unit_word = unit_map.get(unit.lower(), unit)
            return f"{whole} ph·∫©y {decimal_words} {unit_word}"
        
        # S·ªë v·ªõi ƒë∆°n v·ªã vi·∫øt t·∫Øt (1.5k, 2.3m, etc.)
        text = re.sub(r'([\d]+)[.,]([\d]+)\s*([kmb])\b', decimal_currency, text, flags=re.IGNORECASE)
        
        # ƒê∆°n v·ªã ti·ªÅn t·ªá vi·∫øt t·∫Øt
        text = re.sub(r'([\d]+)\s*k\b', r'\1 ngh√¨n', text, flags=re.IGNORECASE)
        text = re.sub(r'([\d]+)\s*m\b', r'\1 tri·ªáu', text, flags=re.IGNORECASE)
        text = re.sub(r'([\d]+)\s*b\b', r'\1 t·ª∑', text, flags=re.IGNORECASE)
        
        # ƒê·ªìng Vi·ªát Nam
        text = re.sub(r'([\d]+(?:[.,][\d]+)?)\s*ƒë\b', r'\1 ƒë·ªìng', text)
        text = re.sub(r'([\d]+(?:[.,][\d]+)?)\s*vnd\b', r'\1 ƒë·ªìng', text, flags=re.IGNORECASE)
        
        # ƒê√¥ la
        text = re.sub(r'\$\s*([\d]+(?:[.,][\d]+)?)', r'\1 ƒë√¥ la', text)
        text = re.sub(r'([\d]+(?:[.,][\d]+)?)\s*\$', r'\1 ƒë√¥ la', text)
        
        return text
    
    def _normalize_percentage(self, text: str) -> str:
        """Convert percentage to words."""
        text = re.sub(r'([\d]+(?:[.,][\d]+)?)\s*%', r'\1 ph·∫ßn trƒÉm', text)
        return text
    
    def _normalize_units(self, text: str) -> str:
        """Convert measurement units to words."""
        def expand_compound_with_number(match):
            number = match.group(1)
            unit1 = match.group(2).lower()
            unit2 = match.group(3).lower()
            full_unit1 = self.units.get(unit1, unit1)
            full_unit2 = self.units.get(unit2, unit2)
            return f"{number} {full_unit1} tr√™n {full_unit2}"
        
        def expand_compound_without_number(match):
            unit1 = match.group(1).lower()
            unit2 = match.group(2).lower()
            full_unit1 = self.units.get(unit1, unit1)
            full_unit2 = self.units.get(unit2, unit2)
            return f"{full_unit1} tr√™n {full_unit2}"
        
        # ƒê∆°n v·ªã ph·ª©c h·ª£p (km/h, m/s, etc.)
        text = re.sub(r'([\d]+(?:[.,][\d]+)?)\s*([a-zA-ZŒº¬µ¬≤¬≥¬∞]+)/([a-zA-ZŒº¬µ¬≤¬≥¬∞0-9]+)\b', 
                     expand_compound_with_number, text)
        text = re.sub(r'\b([a-zA-ZŒº¬µ¬≤¬≥¬∞]+)/([a-zA-ZŒº¬µ¬≤¬≥¬∞0-9]+)\b', 
                     expand_compound_without_number, text)
        
        # ƒê∆°n v·ªã ƒë∆°n: s·∫Øp x·∫øp theo ƒë·ªô d√†i gi·∫£m d·∫ßn ƒë·ªÉ match ƒë√∫ng
        sorted_units = sorted(self.units.items(), key=lambda x: len(x[0]), reverse=True)
        
        # ƒê∆°n v·ªã v·ªõi s·ªë ƒë·ª©ng tr∆∞·ªõc
        for unit, full_name in sorted_units:
            pattern = r'([\d]+(?:[.,][\d]+)?)\s*' + re.escape(unit) + r'\b'
            text = re.sub(pattern, rf'\1 {full_name}', text, flags=re.IGNORECASE)
        
        # ƒê∆°n v·ªã c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát ƒë·ª©ng m·ªôt m√¨nh
        for unit, full_name in sorted_units:
            if any(c in unit for c in '¬≤¬≥¬∞'):
                pattern = r'\b' + re.escape(unit) + r'\b'
                text = re.sub(pattern, full_name, text, flags=re.IGNORECASE)
        
        return text
    
    def _normalize_time(self, text: str) -> str:
        """Convert time notation to words with validation."""
        
        def validate_and_convert_time(match):
            groups = match.groups()
            
            # HH:MM:SS format
            if len(groups) == 3:
                hour, minute, second = groups
                hour_int, minute_int, second_int = int(hour), int(minute), int(second)
                
                if not (0 <= hour_int <= 23):
                    return match.group(0)
                if not (0 <= minute_int <= 59):
                    return match.group(0)
                if not (0 <= second_int <= 59):
                    return match.group(0)
                
                return f"{hour} gi·ªù {minute} ph√∫t {second} gi√¢y"
            
            # HH:MM or HHhMM format
            elif len(groups) == 2:
                hour, minute = groups
                hour_int, minute_int = int(hour), int(minute)
                
                if not (0 <= hour_int <= 23):
                    return match.group(0)
                if not (0 <= minute_int <= 59):
                    return match.group(0)
                
                return f"{hour} gi·ªù {minute} ph√∫t"
            
            # HHh format
            else:
                hour = groups[0]
                hour_int = int(hour)
                
                if not (0 <= hour_int <= 23):
                    return match.group(0)
                
                return f"{hour} gi·ªù"
        
        # Apply patterns
        text = re.sub(r'([\d]{1,2}):([\d]{2}):([\d]{2})', validate_and_convert_time, text)
        text = re.sub(r'([\d]{1,2}):([\d]{2})', validate_and_convert_time, text)
        text = re.sub(r'([\d]{1,2})h([\d]{2})', validate_and_convert_time, text)
        text = re.sub(r'([\d]{1,2})h\b', validate_and_convert_time, text)
        
        return text
    
    def _normalize_date(self, text: str) -> str:
        """Convert date notation to words with validation."""
        
        def is_valid_date(day: str, month: str, year: str) -> bool:
            day_int, month_int, year_int = int(day), int(month), int(year)
            
            if not (1 <= day_int <= 31):
                return False
            if not (1 <= month_int <= 12):
                return False
            
            return True
        
        def date_to_text(match):
            day, month, year = match.groups()
            if is_valid_date(day, month, year):
                return f"ng√†y {day} th√°ng {month} nƒÉm {year}"
            return match.group(0)
        
        def date_iso_to_text(match):
            year, month, day = match.groups()
            if is_valid_date(day, month, year):
                return f"ng√†y {day} th√°ng {month} nƒÉm {year}"
            return match.group(0)
        
        def date_short_year(match):
            day, month, year = match.groups()
            full_year = f"20{year}" if int(year) < 50 else f"19{year}"
            if is_valid_date(day, month, full_year):
                return f"ng√†y {day} th√°ng {month} nƒÉm {full_year}"
            return match.group(0)
        
        # Apply patterns
        text = re.sub(r'\bng√†y\s+([\d]{1,2})[/\-]([\d]{1,2})[/\-]([\d]{4})\b', 
                    lambda m: date_to_text(m).replace('ng√†y ng√†y', 'ng√†y'), text)
        text = re.sub(r'\bng√†y\s+([\d]{1,2})[/\-]([\d]{1,2})[/\-]([\d]{2})\b', 
                    lambda m: date_short_year(m).replace('ng√†y ng√†y', 'ng√†y'), text )
        text = re.sub(r'\b([\d]{4})-([\d]{1,2})-([\d]{1,2})\b', date_iso_to_text, text)
        text = re.sub(r'\b([\d]{1,2})[/\-]([\d]{1,2})[/\-]([\d]{4})\b', date_to_text, text)
        text = re.sub(r'\b([\d]{1,2})[/\-]([\d]{1,2})[/\-]([\d]{2})\b', date_short_year, text)
        
        return text
    
    def _normalize_phone(self, text: str) -> str:
        """Convert phone numbers to digit-by-digit reading."""
        def phone_to_text(match):
            phone = match.group(0)
            phone = re.sub(r'[^\d]', '', phone)
            
            # Chuy·ªÉn +84 th√†nh 0
            if phone.startswith('84') and len(phone) >= 10:
                phone = '0' + phone[2:]
            
            if 10 <= len(phone) <= 11:
                words = [self.digits[int(d)] for d in phone]
                return ' '.join(words) + ' '
            
            return match.group(0)
        
        # S·ªë ƒëi·ªán tho·∫°i Vi·ªát Nam
        text = re.sub(r'(\+84|84)[\s\-\.]?\d[\d\s\-\.]{7,}', phone_to_text, text)
        text = re.sub(r'\b0\d[\d\s\-\.]{8,}', phone_to_text, text)
        
        return text
    
    def _normalize_numbers(self, text: str) -> str:
        """Normalize number formats."""
        # Percentage ƒë√£ x·ª≠ l√Ω
        text = re.sub(r'([\d]+(?:[,.][\d]+)?)%', lambda m: f'{m.group(1)} ph·∫ßn trƒÉm', text)
        
        # X√≥a d·∫•u thousand separator (1.000.000 -> 1000000)
        text = re.sub(r'([\d]{1,3})(?:\.([\d]{3}))+', lambda m: m.group(0).replace('.', ''), text)
        
        # S·ªë th·∫≠p ph√¢n
        def decimal_to_words(match):
            whole = match.group(1)
            decimal = match.group(2)
            decimal_words = ' '.join([self.digits[int(d)] for d in decimal])
            separator = 'ph·∫©y' if ',' in match.group(0) else 'ch·∫•m'
            return f"{whole} {separator} {decimal_words}"
        
        # D·∫•u ph·∫©y th·∫≠p ph√¢n
        text = re.sub(r'([\d]+),([\d]+)', decimal_to_words, text)
        # D·∫•u ch·∫•m th·∫≠p ph√¢n (1-2 ch·ªØ s·ªë)
        text = re.sub(r'([\d]+)\.([\d]{1,2})\b', decimal_to_words, text)
        
        return text
    
    def _read_two_digits(self, n: int) -> str:
        """Read two-digit numbers in Vietnamese."""
        if n < 10:
            return self.digits[n]
        elif n == 10:
            return "m∆∞·ªùi"
        elif n < 20:
            if n == 15:
                return "m∆∞·ªùi lƒÉm"
            return f"m∆∞·ªùi {self.digits[n % 10]}"
        else:
            tens = n // 10
            ones = n % 10
            if ones == 0:
                return f"{self.digits[tens]} m∆∞∆°i"
            elif ones == 1:
                return f"{self.digits[tens]} m∆∞∆°i m·ªët"
            elif ones == 5:
                return f"{self.digits[tens]} m∆∞∆°i lƒÉm"
            else:
                return f"{self.digits[tens]} m∆∞∆°i {self.digits[ones]}"
    
    def _read_three_digits(self, n: int) -> str:
        """Read three-digit numbers in Vietnamese."""
        if n < 100:
            return self._read_two_digits(n)
        
        hundreds = n // 100
        remainder = n % 100
        result = f"{self.digits[hundreds]} trƒÉm"
        
        if remainder == 0:
            return result
        elif remainder < 10:
            result += f" l·∫ª {self.digits[remainder]}"
        else:
            result += f" {self._read_two_digits(remainder)}"
        
        return result
    
    def _convert_number_to_words(self, num: int) -> str:
        """Convert a number to Vietnamese words."""
        if num == 0:
            return "kh√¥ng"
        
        if num < 0:
            return f"√¢m {self._convert_number_to_words(-num)}"
        
        if num >= 1000000000:
            billion = num // 1000000000
            remainder = num % 1000000000
            result = f"{self._read_three_digits(billion)} t·ª∑"
            if remainder > 0:
                result += f" {self._convert_number_to_words(remainder)}"
            return result
        
        elif num >= 1000000:
            million = num // 1000000
            remainder = num % 1000000
            result = f"{self._read_three_digits(million)} tri·ªáu"
            if remainder > 0:
                result += f" {self._convert_number_to_words(remainder)}"
            return result
        
        elif num >= 1000:
            thousand = num // 1000
            remainder = num % 1000
            result = f"{self._read_three_digits(thousand)} ngh√¨n"
            if remainder > 0:
                if remainder < 100:
                    result += f" kh√¥ng trƒÉm {self._read_two_digits(remainder)}"
                else:
                    result += f" {self._read_three_digits(remainder)}"
            return result
        
        else:
            return self._read_three_digits(num)
    
    def _number_to_words(self, text: str) -> str:
        """Convert all remaining numbers to words."""
        def convert_number(match):
            num = int(match.group(0))
            return self._convert_number_to_words(num)
        
        text = re.sub(r'\b[\d]+\b', convert_number, text)
        return text
    
    def _normalize_special_chars(self, text: str) -> str:
        """Handle special characters."""
        text = text.replace('&', ' v√† ')
        text = text.replace('+', ' c·ªông ')
        text = text.replace('=', ' b·∫±ng ')
        text = text.replace('#', ' thƒÉng ')
        
        # Lo·∫°i b·ªè d·∫•u ngo·∫∑c
        text = re.sub(r'[\[\]\(\)\{\}]', ' ', text)
        
        # Lo·∫°i b·ªè d·∫•u g·∫°ch ngang gi·ªØa c√°c t·ª´
        text = re.sub(r'\s+[-‚Äì‚Äî]+\s+', ' ', text)
        
        # Lo·∫°i b·ªè d·∫•u ch·∫•m li√™n ti·∫øp
        text = re.sub(r'\.{2,}', ' ', text)
        text = re.sub(r'\s+\.\s+', ' ', text)
        
        # Gi·ªØ l·∫°i c√°c k√Ω t·ª± ti·∫øng Vi·ªát v√† d·∫•u c√¢u c∆° b·∫£n
        text = re.sub(r'[^\w\s√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë.,!?;:@%]', ' ', text)
        
        return text
    
    def _normalize_whitespace(self, text: str) -> str:
        """Normalize whitespace."""
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        return text



def split_text_into_chunks(text: str, max_chars: int = 256) -> list:
    """
    Split text into chunks at sentence boundaries for TTS synthesis.
    
    Args:
        text: Input text to split
        max_chars: Maximum characters per chunk
        
    Returns:
        List of text chunks
    """
    if len(text) <= max_chars:
        return [text]
    
    # ƒê·ªãnh nghƒ©a c√°c d·∫•u k·∫øt th√∫c c√¢u
    sentence_endings = ['. ', '! ', '? ', '.\n', '!\n', '?\n']
    
    chunks = []
    current_chunk = ""
    
    # T√°ch th√†nh c√°c c√¢u
    sentences = []
    temp = text
    while temp:
        # T√¨m v·ªã tr√≠ k·∫øt th√∫c c√¢u g·∫ßn nh·∫•t
        earliest_end = len(temp)
        for ending in sentence_endings:
            pos = temp.find(ending)
            if pos != -1 and pos < earliest_end:
                earliest_end = pos + len(ending)
        
        if earliest_end < len(temp):
            sentences.append(temp[:earliest_end])
            temp = temp[earliest_end:]
        else:
            sentences.append(temp)
            break
    
    # Gh√©p c√°c c√¢u th√†nh chunk
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= max_chars:
            current_chunk += sentence
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            
            # N·∫øu c√¢u qu√° d√†i, chia nh·ªè h∆°n
            if len(sentence) > max_chars:
                words = sentence.split()
                current_chunk = ""
                for word in words:
                    if len(current_chunk) + len(word) + 1 <= max_chars:
                        current_chunk += word + " "
                    else:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                        current_chunk = word + " "
            else:
                current_chunk = sentence
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks


if __name__ == "__main__":
    normalizer = VietnameseTTSNormalizer()
    
    test_texts = [
        "Gi√° 2.500.000ƒë (gi·∫£m 50%), mua tr∆∞·ªõc 14h30 ng√†y 15/12/2025",
        "Li√™n h·ªá: 0912-345-678 ho·∫∑c email@example.com",
        "T·ªëc ƒë·ªô 120km/h, tr·ªçng l∆∞·ª£ng 75kg",
        "Nhi·ªát ƒë·ªô 36,5¬∞C, ƒë·ªô ·∫©m 80%",
        "S·ªë pi = 3,14159",
        "Gi√° tr·ªã tƒÉng 2.5M, ƒë·∫°t 10B",
        "Nhi·ªát ƒë·ªô -15¬∞C v√†o m√πa ƒë√¥ng",
        "ƒêi·ªán √°p 220V, c√¥ng su·∫•t 2.5kW, t·∫ßn s·ªë 50Hz",
        "C·∫ßn 5l n∆∞·ªõc cho c√¥ng th·ª©c n√†y",
        "V·∫≠n t·ªëc √°nh s√°ng 299792km/s",
        "M·∫≠t ƒë·ªô d√¢n s·ªë 450 ng∆∞·ªùi/km2",
        "H√¥m nay 2025-01-15",
        "G·ªçi +84 912 345 678",
        "Nhi·ªát ƒë·ªô 25¬∞C l√∫c 14:30:45",
    ]
    
    print("=" * 80)
    print("VIETNAMESE TTS NORMALIZATION TEST")
    print("=" * 80)
    
    for text in test_texts:
        print(f"\nüìù Input: {text}")
        normalized = normalizer.normalize(text)
        print(f"üéµ Output: {normalized}")
        print("-" * 80)
